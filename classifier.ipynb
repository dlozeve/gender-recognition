{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use(\"seaborn\")\n",
    "plt.rcParams[\"figure.figsize\"] = 10, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import log_loss, brier_score_loss, precision_score, recall_score, f1_score\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"data/train.data.csv\")\n",
    "y = pd.read_csv(\"data/train.labels.csv\")\n",
    "test_data = pd.read_csv(\"data/test.data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.values\n",
    "y = y.values.ravel()\n",
    "test_data = test_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA & QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "for train, test in skf.split(X, y):\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    lda.fit(X[train,:], y[train])\n",
    "    y_pred = lda.predict_proba(X[test,:])\n",
    "    print(log_loss(y[test], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "for train, test in skf.split(X, y):\n",
    "    qda = QuadraticDiscriminantAnalysis(reg_param=0.01)\n",
    "    qda.fit(X[train,:], y[train])\n",
    "    y_pred = qda.predict_proba(X[test,:])\n",
    "    print(log_loss(y[test], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "clf = xgb.XGBClassifier(max_depth=6, learning_rate=0.1, n_estimators=1000,\n",
    "                       silent=False, objective='binary:logistic', n_jobs=4)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict_proba(X_test)\n",
    "print(log_loss(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "clf = xgb.XGBClassifier(n_jobs=1)\n",
    "param_grid = {\"max_depth\": [3,5,6],\n",
    "             \"learning_rate\": [0.1, 0.01],\n",
    "             \"n_estimators\": [1000, 3000],\n",
    "             \"objective\": [\"binary:logistic\"],\n",
    "             \"reg_lambda\": [0, 0.001, 0.01]}\n",
    "gs = GridSearchCV(clf, param_grid, scoring=\"neg_log_loss\", cv=3, verbose=2, n_jobs=4)\n",
    "gs.fit(X_train, y_train)\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedShuffleSplit(n_splits=3, test_size=0.1)\n",
    "for train, test in skf.split(X, y):\n",
    "    clf = xgb.XGBClassifier(max_depth=6, learning_rate=0.1, n_estimators=1000,\n",
    "                            silent=False, objective='binary:logistic', n_jobs=4)\n",
    "    clf.fit(X[train,:], y[train])\n",
    "    y_pred = clf.predict_proba(X[test,:])\n",
    "    print(log_loss(y[test], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_calibration_curve(est, name, X_train, X_test, y_train, y_test, plot=True):\n",
    "    \"\"\"Plot calibration curve for est w/o and with calibration. \"\"\"\n",
    "    # Calibrated with isotonic calibration\n",
    "    isotonic = CalibratedClassifierCV(est, cv=2, method='isotonic')\n",
    "\n",
    "    # Calibrated with sigmoid calibration\n",
    "    sigmoid = CalibratedClassifierCV(est, cv=2, method='sigmoid')\n",
    "\n",
    "    # Logistic regression with no calibration as baseline\n",
    "    lr = LogisticRegression(C=1., solver='lbfgs')\n",
    "\n",
    "    if plot:\n",
    "        fig = plt.figure(1, figsize=(10, 10))\n",
    "        ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "        ax2 = plt.subplot2grid((3, 1), (2, 0))\n",
    "        ax1.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "    best_logloss = 100\n",
    "    \n",
    "    for clf, name in [(lr, 'Logistic'),\n",
    "                      (est, name),\n",
    "                      (isotonic, name + ' + Isotonic'),\n",
    "                      (sigmoid, name + ' + Sigmoid')]:\n",
    "        t0 = time()\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        t = time()\n",
    "        if hasattr(clf, \"predict_proba\"):\n",
    "            prob_pos = clf.predict_proba(X_test)[:, 1]\n",
    "        else:  # use decision function\n",
    "            prob_pos = clf.decision_function(X_test)\n",
    "            prob_pos = \\\n",
    "                (prob_pos - prob_pos.min()) / (prob_pos.max() - prob_pos.min())\n",
    "\n",
    "        clf_score = brier_score_loss(y_test, prob_pos, pos_label=y.max())\n",
    "        print(\"%s:\" % name)\n",
    "        print(\"\\tPrecision: %1.3f\" % precision_score(y_test, y_pred))\n",
    "        print(\"\\tRecall: %1.3f\" % recall_score(y_test, y_pred))\n",
    "        logloss = log_loss(y_test, prob_pos)\n",
    "        print(\"\\tLog_loss: %1.3f\" % logloss)\n",
    "        print(\"\\tTime: %1.2f\\n\" % (t-t0))\n",
    "        \n",
    "        if logloss < best_logloss:\n",
    "            best_logloss = logloss\n",
    "            best_clf = name\n",
    "            best_time = t-t0\n",
    "\n",
    "        fraction_of_positives, mean_predicted_value = \\\n",
    "            calibration_curve(y_test, prob_pos, n_bins=10)\n",
    "        \n",
    "        if plot:\n",
    "            ax1.plot(mean_predicted_value, fraction_of_positives, \"s-\",\n",
    "                     label=\"%s (%1.3f)\" % (name, clf_score))\n",
    "\n",
    "            ax2.hist(prob_pos, range=(0, 1), bins=10, label=name,\n",
    "                     histtype=\"step\", lw=2)\n",
    "\n",
    "    if plot:\n",
    "        ax1.set_ylabel(\"Fraction of positives\")\n",
    "        ax1.set_ylim([-0.05, 1.05])\n",
    "        ax1.legend(loc=\"lower right\")\n",
    "        ax1.set_title('Calibration plots  (reliability curve)')\n",
    "\n",
    "        ax2.set_xlabel(\"Mean predicted value\")\n",
    "        ax2.set_ylabel(\"Count\")\n",
    "        ax2.legend(loc=\"upper center\", ncol=2)\n",
    "\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    return best_clf, best_logloss, t-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "clf = xgb.XGBClassifier(max_depth=4, learning_rate=0.1, n_estimators=1000,\n",
    "                       silent=False, objective='binary:logistic', n_jobs=4)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict_proba(X_test)\n",
    "print(log_loss(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal = CalibratedClassifierCV(clf, method=\"sigmoid\", cv=3)\n",
    "cal.fit(X_train, y_train)\n",
    "y_pred = cal.predict_proba(X_test)\n",
    "print(log_loss(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_raw = KNeighborsClassifier(n_neighbors=10, p=2, n_jobs=-1)\n",
    "best_model = CalibratedClassifierCV(best_model_raw, cv=2, method='isotonic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedShuffleSplit(n_splits=3, test_size=0.1)\n",
    "for train, test in skf.split(X, y):\n",
    "    X_train = X[train,:]\n",
    "    y_train = y[train]\n",
    "    X_test = X[test,:]\n",
    "    y_test = y[test]\n",
    "    best_model_raw.fit(X_train, y_train)\n",
    "    y_pred = best_model_raw.predict_proba(X_test)\n",
    "    print(log_loss(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedShuffleSplit(n_splits=3, test_size=0.1)\n",
    "for train, test in skf.split(X, y):\n",
    "    X_train = X[train,:]\n",
    "    y_train = y[train]\n",
    "    X_test = X[test,:]\n",
    "    y_test = y[test]\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict_proba(X_test)\n",
    "    print(log_loss(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier(max_depth=6, learning_rate=0.1, n_estimators=1000,\n",
    "                        silent=False, objective='binary:logistic', n_jobs=4)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_pred = clf.predict_proba(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_pred[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'Id':range(1,15001), 'ProbFemale':test_data_pred[:,1]})\n",
    "submission = submission[['Id','ProbFemale']]\n",
    "submission.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
