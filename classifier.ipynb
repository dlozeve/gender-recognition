{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use(\"seaborn\")\n",
    "plt.rcParams[\"figure.figsize\"] = 10, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import log_loss, brier_score_loss, precision_score, recall_score, f1_score\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"data/train.data.csv\")\n",
    "y = pd.read_csv(\"data/train.labels.csv\")\n",
    "test_data = pd.read_csv(\"data/test.data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.values\n",
    "y = y.values.ravel()\n",
    "test_data = test_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA & QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17240538893180649\n",
      "0.17850714284219815\n",
      "0.16548403451670984\n",
      "0.17610640403466382\n",
      "0.16243686460127657\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "for train, test in skf.split(X, y):\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    lda.fit(X[train,:], y[train])\n",
    "    y_pred = lda.predict_proba(X[test,:])\n",
    "    print(log_loss(y[test], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16961958036289376\n",
      "0.15306646473014543\n",
      "0.15122028501593165\n",
      "0.1561026532556051\n",
      "0.1351773363234211\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "for train, test in skf.split(X, y):\n",
    "    qda = QuadraticDiscriminantAnalysis(reg_param=0.01)\n",
    "    qda.fit(X[train,:], y[train])\n",
    "    y_pred = qda.predict_proba(X[test,:])\n",
    "    print(log_loss(y[test], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10298208615287861\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "clf = xgb.XGBClassifier(max_depth=6, learning_rate=0.1, n_estimators=1000,\n",
    "                       silent=False, objective='binary:logistic', n_jobs=4)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict_proba(X_test)\n",
    "print(log_loss(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=1000, objective=binary:logistic, reg_lambda=0 \n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=1000, objective=binary:logistic, reg_lambda=0 \n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=1000, objective=binary:logistic, reg_lambda=0 \n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=1000, objective=binary:logistic, reg_lambda=0.001 \n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=1000, objective=binary:logistic, reg_lambda=0.001, total= 1.2min\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=1000, objective=binary:logistic, reg_lambda=0.001 \n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=1000, objective=binary:logistic, reg_lambda=0, total= 1.2min\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=1000, objective=binary:logistic, reg_lambda=0, total= 1.2min\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=1000, objective=binary:logistic, reg_lambda=0.001 \n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=1000, objective=binary:logistic, reg_lambda=0.01 \n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=1000, objective=binary:logistic, reg_lambda=0, total= 1.2min\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=1000, objective=binary:logistic, reg_lambda=0.01 \n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=1000, objective=binary:logistic, reg_lambda=0.001, total= 1.4min\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=1000, objective=binary:logistic, reg_lambda=0.01 \n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=1000, objective=binary:logistic, reg_lambda=0.001, total= 1.4min\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=3000, objective=binary:logistic, reg_lambda=0 \n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=1000, objective=binary:logistic, reg_lambda=0.01, total= 1.5min\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=3000, objective=binary:logistic, reg_lambda=0 \n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=1000, objective=binary:logistic, reg_lambda=0.01, total= 1.5min\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=3000, objective=binary:logistic, reg_lambda=0 \n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=1000, objective=binary:logistic, reg_lambda=0.01, total= 1.3min\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=3000, objective=binary:logistic, reg_lambda=0.001 \n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=3000, objective=binary:logistic, reg_lambda=0, total= 3.4min\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=3000, objective=binary:logistic, reg_lambda=0.001 \n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=3000, objective=binary:logistic, reg_lambda=0, total= 3.3min\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=3000, objective=binary:logistic, reg_lambda=0.001 \n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=3000, objective=binary:logistic, reg_lambda=0, total= 3.3min\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=3000, objective=binary:logistic, reg_lambda=0.01 \n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=3000, objective=binary:logistic, reg_lambda=0.001, total= 3.2min\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=3000, objective=binary:logistic, reg_lambda=0.01 \n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=3000, objective=binary:logistic, reg_lambda=0.001, total= 3.2min\n",
      "[CV] learning_rate=0.1, max_depth=3, n_estimators=3000, objective=binary:logistic, reg_lambda=0.01 \n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=3000, objective=binary:logistic, reg_lambda=0.01, total= 3.2min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=1000, objective=binary:logistic, reg_lambda=0 \n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=3000, objective=binary:logistic, reg_lambda=0.001, total= 3.3min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=1000, objective=binary:logistic, reg_lambda=0 \n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=3000, objective=binary:logistic, reg_lambda=0.01, total= 3.2min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=1000, objective=binary:logistic, reg_lambda=0 \n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=1000, objective=binary:logistic, reg_lambda=0, total= 1.7min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=1000, objective=binary:logistic, reg_lambda=0.001 \n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=1000, objective=binary:logistic, reg_lambda=0, total= 1.8min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=1000, objective=binary:logistic, reg_lambda=0.001 \n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=1000, objective=binary:logistic, reg_lambda=0, total= 1.7min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=1000, objective=binary:logistic, reg_lambda=0.001 \n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=3000, objective=binary:logistic, reg_lambda=0.01, total= 3.3min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=1000, objective=binary:logistic, reg_lambda=0.01 \n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=1000, objective=binary:logistic, reg_lambda=0.001, total= 1.8min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=1000, objective=binary:logistic, reg_lambda=0.01 \n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=1000, objective=binary:logistic, reg_lambda=0.001, total= 1.8min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=1000, objective=binary:logistic, reg_lambda=0.01 \n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=1000, objective=binary:logistic, reg_lambda=0.001, total= 1.7min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=3000, objective=binary:logistic, reg_lambda=0 \n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=1000, objective=binary:logistic, reg_lambda=0.01, total= 1.7min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=3000, objective=binary:logistic, reg_lambda=0 \n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=1000, objective=binary:logistic, reg_lambda=0.01, total= 1.7min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=3000, objective=binary:logistic, reg_lambda=0 \n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=1000, objective=binary:logistic, reg_lambda=0.01, total= 1.7min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=3000, objective=binary:logistic, reg_lambda=0.001 \n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=3000, objective=binary:logistic, reg_lambda=0, total= 3.0min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=3000, objective=binary:logistic, reg_lambda=0.001 \n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=3000, objective=binary:logistic, reg_lambda=0, total= 3.1min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=3000, objective=binary:logistic, reg_lambda=0.001 \n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=3000, objective=binary:logistic, reg_lambda=0, total= 3.1min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=3000, objective=binary:logistic, reg_lambda=0.01 \n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=3000, objective=binary:logistic, reg_lambda=0.001, total= 3.0min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=3000, objective=binary:logistic, reg_lambda=0.01 \n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=3000, objective=binary:logistic, reg_lambda=0.001, total= 3.3min\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=3000, objective=binary:logistic, reg_lambda=0.01 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7c26ff18085f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m              \"reg_lambda\": [0, 0.001, 0.01]}\n\u001b[1;32m      8\u001b[0m \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"neg_log_loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "clf = xgb.XGBClassifier(n_jobs=1)\n",
    "param_grid = {\"max_depth\": [3,5,6],\n",
    "             \"learning_rate\": [0.1, 0.01],\n",
    "             \"n_estimators\": [1000, 3000],\n",
    "             \"objective\": [\"binary:logistic\"],\n",
    "             \"reg_lambda\": [0, 0.001, 0.01]}\n",
    "gs = GridSearchCV(clf, param_grid, scoring=\"neg_log_loss\", cv=3, verbose=2, n_jobs=4)\n",
    "gs.fit(X_train, y_train)\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedShuffleSplit(n_splits=3, test_size=0.1)\n",
    "for train, test in skf.split(X, y):\n",
    "    clf = xgb.XGBClassifier(max_depth=6, learning_rate=0.1, n_estimators=1000,\n",
    "                            silent=False, objective='binary:logistic', n_jobs=4)\n",
    "    clf.fit(X[train,:], y[train])\n",
    "    y_pred = clf.predict_proba(X[test,:])\n",
    "    print(log_loss(y[test], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_calibration_curve(est, name, X_train, X_test, y_train, y_test, plot=True):\n",
    "    \"\"\"Plot calibration curve for est w/o and with calibration. \"\"\"\n",
    "    # Calibrated with isotonic calibration\n",
    "    isotonic = CalibratedClassifierCV(est, cv=2, method='isotonic')\n",
    "\n",
    "    # Calibrated with sigmoid calibration\n",
    "    sigmoid = CalibratedClassifierCV(est, cv=2, method='sigmoid')\n",
    "\n",
    "    # Logistic regression with no calibration as baseline\n",
    "    lr = LogisticRegression(C=1., solver='lbfgs')\n",
    "\n",
    "    if plot:\n",
    "        fig = plt.figure(1, figsize=(10, 10))\n",
    "        ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "        ax2 = plt.subplot2grid((3, 1), (2, 0))\n",
    "        ax1.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "    best_logloss = 100\n",
    "    \n",
    "    for clf, name in [(lr, 'Logistic'),\n",
    "                      (est, name),\n",
    "                      (isotonic, name + ' + Isotonic'),\n",
    "                      (sigmoid, name + ' + Sigmoid')]:\n",
    "        t0 = time()\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        t = time()\n",
    "        if hasattr(clf, \"predict_proba\"):\n",
    "            prob_pos = clf.predict_proba(X_test)[:, 1]\n",
    "        else:  # use decision function\n",
    "            prob_pos = clf.decision_function(X_test)\n",
    "            prob_pos = \\\n",
    "                (prob_pos - prob_pos.min()) / (prob_pos.max() - prob_pos.min())\n",
    "\n",
    "        clf_score = brier_score_loss(y_test, prob_pos, pos_label=y.max())\n",
    "        print(\"%s:\" % name)\n",
    "        print(\"\\tPrecision: %1.3f\" % precision_score(y_test, y_pred))\n",
    "        print(\"\\tRecall: %1.3f\" % recall_score(y_test, y_pred))\n",
    "        logloss = log_loss(y_test, prob_pos)\n",
    "        print(\"\\tLog_loss: %1.3f\" % logloss)\n",
    "        print(\"\\tTime: %1.2f\\n\" % (t-t0))\n",
    "        \n",
    "        if logloss < best_logloss:\n",
    "            best_logloss = logloss\n",
    "            best_clf = name\n",
    "            best_time = t-t0\n",
    "\n",
    "        fraction_of_positives, mean_predicted_value = \\\n",
    "            calibration_curve(y_test, prob_pos, n_bins=10)\n",
    "        \n",
    "        if plot:\n",
    "            ax1.plot(mean_predicted_value, fraction_of_positives, \"s-\",\n",
    "                     label=\"%s (%1.3f)\" % (name, clf_score))\n",
    "\n",
    "            ax2.hist(prob_pos, range=(0, 1), bins=10, label=name,\n",
    "                     histtype=\"step\", lw=2)\n",
    "\n",
    "    if plot:\n",
    "        ax1.set_ylabel(\"Fraction of positives\")\n",
    "        ax1.set_ylim([-0.05, 1.05])\n",
    "        ax1.legend(loc=\"lower right\")\n",
    "        ax1.set_title('Calibration plots  (reliability curve)')\n",
    "\n",
    "        ax2.set_xlabel(\"Mean predicted value\")\n",
    "        ax2.set_ylabel(\"Count\")\n",
    "        ax2.legend(loc=\"upper center\", ncol=2)\n",
    "\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    return best_clf, best_logloss, t-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10843816575314781\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "clf = xgb.XGBClassifier(max_depth=4, learning_rate=0.1, n_estimators=1000,\n",
    "                       silent=False, objective='binary:logistic', n_jobs=4)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict_proba(X_test)\n",
    "print(log_loss(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11870577046594617\n"
     ]
    }
   ],
   "source": [
    "cal = CalibratedClassifierCV(clf, method=\"sigmoid\", cv=3)\n",
    "cal.fit(X_train, y_train)\n",
    "y_pred = cal.predict_proba(X_test)\n",
    "print(log_loss(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_raw = KNeighborsClassifier(n_neighbors=10, p=2, n_jobs=-1)\n",
    "best_model = CalibratedClassifierCV(best_model_raw, cv=2, method='isotonic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09674013165354484\n",
      "0.19575744578122165\n",
      "0.15338676237061843\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedShuffleSplit(n_splits=3, test_size=0.1)\n",
    "for train, test in skf.split(X, y):\n",
    "    X_train = X[train,:]\n",
    "    y_train = y[train]\n",
    "    X_test = X[test,:]\n",
    "    y_test = y[test]\n",
    "    best_model_raw.fit(X_train, y_train)\n",
    "    y_pred = best_model_raw.predict_proba(X_test)\n",
    "    print(log_loss(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09508256646248019\n",
      "0.07537304021232892\n",
      "0.08749876300402494\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedShuffleSplit(n_splits=3, test_size=0.1)\n",
    "for train, test in skf.split(X, y):\n",
    "    X_train = X[train,:]\n",
    "    y_train = y[train]\n",
    "    X_test = X[test,:]\n",
    "    y_test = y[test]\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict_proba(X_test)\n",
    "    print(log_loss(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=6, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=4, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=False, subsample=1)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(max_depth=6, learning_rate=0.1, n_estimators=1000,\n",
    "                        silent=False, objective='binary:logistic', n_jobs=4)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_pred = clf.predict_proba(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.8711992e-04, 9.2626095e-01, 3.6046476e-04, ..., 9.9979252e-01,\n",
       "       9.9992740e-01, 9.3594182e-01], dtype=float32)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_pred[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'Id':range(1,15001), 'ProbFemale':test_data_pred[:,1]})\n",
    "submission = submission[['Id','ProbFemale']]\n",
    "submission.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
